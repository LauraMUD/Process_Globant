{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list=['./departments.csv','./jobs.csv','./hired_employees.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MySQL database\n",
    "connection = create_engine(\"mysql+mysqldb://globantuser:pruebatecnica123@localhost/process_globant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load the data into a pandas dataframe.\"\"\"\n",
    "    df = pd.read_csv(file_path, delimiter=',', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_data(df):\n",
    "    \"\"\"Validate the data in the dataframe.\"\"\"\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"Missing values:\")\n",
    "        print(missing_values)\n",
    "        return False\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(\"Duplicate rows:\")\n",
    "        print(duplicates)\n",
    "        return False\n",
    "    \n",
    "    # Covert data types in each column\n",
    "    #df['departments_name'] = df['departments_name'].astype(pd.StringDtype())\n",
    "    #df['job_name'] = df['job_name'].astype(pd.StringDtype())\n",
    "    #df['employee_name'] = df['employee_name'].astype(pd.StringDtype())\n",
    "    #df['hired_date'] = pd.to_datetime(df['hired_date'])\n",
    "\n",
    "\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept=load_data(path_list[0])\n",
    "df_dept.columns =['iddepartments', 'departments_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data(df_dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job=load_data(path_list[1])\n",
    "df_job.columns =['idjobs', 'job_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data(df_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_he=load_data(path_list[2])\n",
    "df_he.columns =['idhired_employees', 'employee_name','hired_date','departments_code','job_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "idhired_employees     0\n",
      "employee_name        19\n",
      "hired_date           14\n",
      "departments_code     21\n",
      "job_code             16\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data(df_he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2803176997.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    @app.route(\"/api/transactions\", methods=[\"POST\"])\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# API endpoint to receive new data for the transactions table and insert it into the database\n",
    "@app.route(\"/api/data\", methods=[\"POST\"])\n",
    "def insert_data(df, connector, table_name):\n",
    "     # Get the data from the request\n",
    "    df = request.get_json()\n",
    "    # Validate data\n",
    "    if not validate_data(df):\n",
    "        return \"Invalid data\", 400\n",
    "    if len(df)>1000:\n",
    "        return \"Too many rows, maximum is 1000\"\n",
    "    #Must be append, because we start from the fact that the table was previously created in MySQL\n",
    "    df.to_sql(name=\"table_name\", con=connector, if_exists=\"append\", index=False, chunksize = 1000, method='multi')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
